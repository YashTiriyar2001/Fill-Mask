# -*- coding: utf-8 -*-
"""mask_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l7252R7WdJZFlQuoZocwUo9xhf_SII6f
"""

!pip install transformers
!pip install datasets
!apt install git-lfs
!git config --global user.email "you@example.com"
!git config --global user.name "Your Name"

from google.colab import drive
drive.mount('/content/drive')

from transformers import pipeline as transformers_pipeline
from transformers import TFAutoModelForCausalLM
from transformers import AutoTokenizer
from datasets import load_dataset
from transformers import pipeline

class mask_pipeline:
  
  def model(self, conf):
    try:
      model = TFAutoModelForCausalLM.from_pretrained(conf["model"])
    except:
      print("unable to load model. Going for pre defined model")
      model = TFAutoModelForCausalLM.from_pretrained(conf["pretrained_model"])
    return model

  def run_pipeline(self, conf, model):
    mask_filler = pipeline(
      "fill-mask", 
      "Rocketknight1/distilroberta-base-finetuned-wikitext2",
      framework="tf",
    )
    return mask_filler
  
  def predict(self, mask_filler, conf):
    print(mask_filler(conf["statement"], conf["top_k"]))
    
  
  def run(self,conf):
    defined_model = self.model(conf)
    mask_filler = self.run_pipeline(conf, defined_model)
    self.predict(mask_filler, conf)



conf = {}
conf["model"] = "/content/drive/MyDrive/Accure.ai/Mask_model/model"
conf["tokenizer"] = "/content/drive/MyDrive/Accure.ai/Mask_model/tokenizer"
conf["top_k"] = 3
conf["statement"] = "The Gulf War was a conflict that took place in <mask> in 1990-1991."
mask = mask_pipeline()
mask.run(conf)

